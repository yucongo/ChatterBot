{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Machine Translation with Seq2Seq in Keras-Malik-22nd-article-.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1DxX7byejxe_lknoZXdtmk9zlaAVtm_Zf",
      "authorship_tag": "ABX9TyOHvL0nUX5bUesH1BvZ4KbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yucongo/ChatterBot/blob/master/Neural_Machine_Translation_with_Seq2Seq_in_Keras_Malik_22nd_article_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBJGsCGda3ew",
        "colab_type": "text"
      },
      "source": [
        "### 22n Neural Machine Translation with Seq2Seq in Keras\n",
        "Usman Malik • October 09, 2019\n",
        "https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flm920YubQxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "refer also to win10 playground\\neural-machine-translation\n",
        "'''\n",
        "import os, sys\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0tNINmGjnLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path(\"/content/drive/My Drive/data\").exists()\n",
        "# !ls '/content/drive/My Drive/data'\n",
        "# !mkdir -p /contend/drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO_NmtbwCX7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/joshbode/58fac7ababc700f51e2a9ecdebe563ad\n",
        "import sys\n",
        "import logging\n",
        "from typing import Optional, Dict\n",
        "\n",
        "try:\n",
        "  import colorama\n",
        "except ModuleNotFoundError:\n",
        "  get_ipython().system(\"pip install colorama\")\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "\n",
        "class ColoredFormatter(logging.Formatter):\n",
        "    \"\"\"Colored log formatter.\"\"\"\n",
        "\n",
        "    def __init__(self, *args, colors: Optional[Dict[str, str]]=None, **kwargs) -> None:\n",
        "        \"\"\"Initialize the formatter with specified format strings.\"\"\"\n",
        "\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.colors = colors if colors else {}\n",
        "\n",
        "    def format(self, record) -> str:\n",
        "        \"\"\"Format the specified record as text.\"\"\"\n",
        "\n",
        "        record.color = self.colors.get(record.levelname, '')\n",
        "        record.reset = Style.RESET_ALL\n",
        "\n",
        "        return super().format(record)\n",
        "\n",
        "\n",
        "formatter = ColoredFormatter(\n",
        "    '{asctime} |{color} {levelname:8} {reset}| ln-{lineno} |{color} {message}',\n",
        "    # '{asctime} |{color} {levelname:8} {reset}| {name} | {message}',\n",
        "    style='{', datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    colors={\n",
        "        'DEBUG': Fore.CYAN,\n",
        "        'INFO': Fore.GREEN,\n",
        "        'WARNING': Fore.YELLOW,\n",
        "        'ERROR': Fore.RED,\n",
        "        'CRITICAL': Fore.RED + Back.WHITE + Style.BRIGHT,\n",
        "    }\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYHtpqiGuDX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd\n",
        "# !ls /content/drive/'My Drive'/data\n",
        "import re\n",
        "import logging\n",
        "import platform\n",
        "try: \n",
        "  import logzero\n",
        "except ModuleNotFoundError:\n",
        "  get_ipython().system(\"pip install logzero\")\n",
        "import logzero\n",
        "from logzero import logger\n",
        "# formatter = logging.Formatter('%(levelname)s:%(lineno)s: %(message)s');\n",
        "logzero.formatter(formatter)\n",
        "logzero.loglevel(10)\n",
        "\n",
        "node = platform.node()\n",
        "if re.findall(r\"[\\da-z]{11,}\", node):\n",
        "  loc = \"colab\"\n",
        "elif \"hamming\" in node:\n",
        "  loc = \"win10\"\n",
        "\n",
        "if loc in ['colab']:\n",
        "  from pathlib import Path\n",
        "  if not Path(\"/content/drive/My Drive/data\").exists():\n",
        "    from google.colab import drive\n",
        "    !mkdir -p /contend/drive\n",
        "    try:\n",
        "      drive.mount(\"/countent/drive\")\n",
        "    except Exception as exc:\n",
        "      logger.error(\"drive.mount(\\\"/countent/drive\\\")  exc: %s\", exc)\n",
        "logger.info(\"pwd: %s\", os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PQPAYAMbuII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# %%bash\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "LSTM_NODES = 256\n",
        "NUM_SENTENCES = 20000\n",
        "MAX_SENTENCE_LENGTH = 50\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEi66D12MK4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# win10 playground neural-machine-translation load.py\n",
        "\n",
        "# get_ipython().system('rm %s' % filename)\n",
        "\n",
        "# http://www.manythings.org/anki/deu-eng.zip\n",
        "lang =\"cmn\"\n",
        "filename = f\"{lang}-eng.zip\"\n",
        "os.chdir(r\"/content/drive/My Drive/data\")\n",
        "if not Path(filename).exists():\n",
        "  !wget -c http://www.manythings.org/anki/{filename}\n",
        "# !curl -O http://www.manythings.org/anki/{filename}\n",
        "# !wget -c http://www.manythings.org/anki/{filename}\n",
        "\n",
        "# get_ipython().system('ls')\n",
        "# get_ipython().system('cp -f deu-eng.zip drive/My\\ Drive/data')\n",
        "# get_ipython().system('ls /content/drive/My\\ Drive/data')\n",
        "# !unzip -tv {filename}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKwNa4vbdGgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from pathlib import Path\n",
        "\n",
        "lang = 'deu'\n",
        "lang = 'cmn'\n",
        "filename = f'{lang}-eng.zip'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UU0ZNY8vQ8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_name = '.'\n",
        "if Path('/content/drive/My Drive/data').exists():\n",
        "  dir_name = '/content/drive/My Drive/data'\n",
        "\n",
        "zfilename = f'{dir_name}/{lang}-eng.zip'\n",
        "# !unzip -t \"{zfilename}\"\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "assert Path(zfilename).exists(), f'{zfilename} does not exits.'\n",
        "from pprint import pprint\n",
        "filename = f'{lang}.txt'\n",
        "\n",
        "with ZipFile(zfilename) as zipfile, zipfile.open(filename) as fha: tot_lines = len([*fha])\n",
        "# tot_lines = len([*fha])  # 204574\n",
        "# logger.debug(\"tot_lines: %s\", tot_lines)\n",
        "# tot_lines = 204574  # lang = 'de'\n",
        "# lang: cmn, tot_lines: 22075\n",
        "\n",
        "logger.info(\"lang: %s, tot_lines: %s, zfilename: %s\", lang, tot_lines, zfilename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTSMQcmX6k8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "break_on = 10  # tot_lines\n",
        "break_on = NUM_SENTENCES\n",
        "with ZipFile(zfilename) as zipfile, zipfile.open(filename) as fha:\n",
        "    # zipfile.filelist:  filename='deu.txt', filename='_about.txt'\n",
        "    for idx, line in enumerate(fha):\n",
        "        if idx > break_on - 1: break\n",
        "        split = line.decode().split(sep=\"\\t\")\n",
        "        if len(split) > 1:\n",
        "          # en, de, *_ = split \n",
        "          entry1, entry2, *_ = split\n",
        "          # pprint([en, de, ])\n",
        "        # pprint(line.decode())\n",
        "\n",
        "        input, output = entry2, entry1\n",
        "        input_sentences.append(input)\n",
        "        output_sentences.append(output + ' <eos>')\n",
        "        output_sentences_inputs.append('<sos> ' + output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ci2vDtDVZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import reprlib\n",
        "# logger.debug(\"input_sentences[:3]: %s, input_sentences[:3]: %s, output_sentences_inputs[:3]: %s\", input_sentences[:3], output_sentences_inputs[:3], output_sentences[:3])\n",
        "print('input_sentences:',reprlib.repr(input_sentences))\n",
        "print('output_sentences:',reprlib.repr(output_sentences))\n",
        "print('output_sentences_inputs:',reprlib.repr(output_sentences_inputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDlGgD8qKVn7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuJhmd-iKGR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import reprlib\n",
        "logzero.loglevel(10)\n",
        "logger.debug(reprlib.repr(input_sentences))\n",
        "logger.debug(reprlib.repr(output_sentences_inputs))\n",
        "logger.debug(reprlib.repr(output_sentences))\n",
        "logger.debug(\"len(input_sentences): %s\", len(input_sentences))\n",
        "print(\"num samples input:\", len(input_sentences))\n",
        "print(\"num samples output:\", len(output_sentences))\n",
        "print(\"num samples output input:\", len(output_sentences_inputs))\n",
        "\n",
        "print(172, input_sentences[172])\n",
        "print(output_sentences[172])\n",
        "print(output_sentences_inputs[172])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5uP5xj_V6Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "if lang in ['cmn']:\n",
        "    input_tokenizer = Tokenizer(\n",
        "        num_words=MAX_NUM_WORDS,\n",
        "        char_level=True,\n",
        "        oov_token='',\n",
        "    )\n",
        "else:\n",
        "    input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "logger.debug(\"MAX_NUM_WORDS: %s\", MAX_NUM_WORDS)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "# idx2word_target = {v:k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
        "\n",
        "# [D 200508 14:12:57 <ipython-input-25-8209ac589f74>:12] MAX_NUM_WORDS: 20000\n",
        "# Total unique words in the input: 3271\n",
        "# Length of longest sentence in input: 23"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5nFt539XGXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def idx2word(idx, word2idx=word2idx_inputs):\n",
        "  return [k for k, v in word2idx.items() if v == idx]\n",
        "in_len_list = [len(_) for _ in input_integer_seq]\n",
        "argmax_in, max_in = np.argmax(in_len_list), np.max(in_len_list)\n",
        "logger.debug(\"argmax_in: %s, max_in: %s, %s\", argmax_in, max_in, input_integer_seq[argmax_in])\n",
        "logger.debug(\"longest input: %s, \", [idx2word(_, word2idx_inputs) for _ in input_integer_seq[argmax_in]])\n",
        "''.join([''.join(_) for _ in [idx2word(_, word2idx_inputs) for _ in input_integer_seq[argmax_in]]])\n",
        "# DEBUG:5: argmax_in: 16521, max_in: 23, [12, 6, 13, 150, 18, 4, 83, 116, 35, 44, 194, 6, 4, 215, 171, 621, 10, 93, 134, 4, 215, 171, 2]\n",
        "# DEBUG:6: longest input: [['在'], ['你'], ['有'], ['需'], ['要'], ['的'], ['時'], ['候'], ['，'], ['會'], ['幫'], ['你'], ['的'], ['朋'], ['友'], ['才'], ['是'], ['真'], ['正'], ['的'], ['朋'], ['友'], ['。']], \n",
        "# '在你有需要的時候，會幫你的朋友才是真正的朋友。'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1SVLbXOYoFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[''.join(_) for _ in [idx2word(_, word2idx_inputs) for _ in range(15)]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFFn_hCXAsQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger.debug(\"input_integer_seq: %s\", reprlib.repr(input_sentences))\n",
        "logger.debug(\"input_integer_seq: %s\", reprlib.repr(input_integer_seq))\n",
        "# [D 200508 14:13:26 <ipython-input-26-bb9286a73bf7>:1] input_integer_seq: ['嗨。', '你好。', '你用跑的。', '等等！', '等一下！', '你好。', ...]\n",
        "# [D 200508 14:13:26 <ipython-input-26-bb9286a73bf7>:2] input_integer_seq: [[1879, 2], [6, 31, 2], [6, 103, 394, 4, 2], [192, 192, 164], [192, 11, 47, 164], [6, 31, 2], ...]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpijcDfK9Uph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def idx2word(idx, word2idx=word2idx_inputs):\n",
        "  return [k for k, v in word2idx.items() if v == idx]\n",
        "# for sent in [[1879, 2], [6, 31, 2], [6, 103, 394, 4, 2], [192, 192, 164], [192, 11, 47, 164], [6, 31, 2],]:\n",
        "#   print(sent, [idx2word(elm) for elm in sent])\n",
        "for idx, sent in  enumerate(input_integer_seq[:20]): \n",
        "    print(input_sentences[idx], sent, [idx2word(elm) for elm in sent])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LioIUBOp33sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##################\n",
        "# output_sequences\n",
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "# idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "# idx2word_target = {v:k for k, v in word2idx_outputs.items()}\n",
        "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)\n",
        "# en Total unique words in the output: 9102\n",
        "# en Length of longest sentence in the output: 13\n",
        "\n",
        "_ = \"\"\"\n",
        "Total unique words in the output: 5290\n",
        "Length of longest sentence in the output: 6\n",
        "\n",
        "In [430]: [(k, v) for k, v in word2idx_outputs.items() if v==1]\n",
        "Out[430]: [('<eos>', 1)]\n",
        "In [431]: [(k, v) for k, v in word2idx_outputs.items() if v==0]\n",
        "Out[431]: []\n",
        "[('<sos>', 2)]/[('i', 3)]/[('the', 4)]\n",
        "[('inner', 9102)]\n",
        "\n",
        "In [436]: [(k, v) for k, v in word2idx_outputs.items() if v==9103]\n",
        "Out[436]: []\n",
        "\n",
        "Total unique words in the output: 9025\n",
        "Length of longest sentence in the output: 13\n",
        "# \"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXXwRBvP2o2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
        "print(\"encoder_input_sequences[172]:\", encoder_input_sequences[172])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWwBYBjL3AEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
        "print(\"decoder_input_sequences[172]:\", decoder_input_sequences[172])\n",
        "print([idx2word(elm, word2idx_outputs) for elm in [2, 173, 475]])\n",
        "# [('<sos>', 2)] [('let', 145)] [('me', 24)]  [('in.', 482)]\n",
        "# -> <sos> let me in.\n",
        "# decoder_input_sequences.shape: (20000, 13)  # 20000 sents of length 13\n",
        "# decoder_input_sequences[172]: [  2 173 475   0   0   0   0   0   0   0   0   0   0]\n",
        "# [['<sos>'], ['keep'], ['them.']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS0vqtEqS9-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(word2idx_outputs['ill'])  # 3446\n",
        "out_len_list = [len(_) for _ in output_input_integer_seq]\n",
        "argmax = np.argmax(out_len_list)  # 19929 sos i will give you a call as soon as i get home.\n",
        "logger.debug(\"\\n\\tdecoder_input_sequences: %s, %s\", \n",
        "  output_input_integer_seq[argmax:argmax + 1], argmax)\n",
        "logger.debug(\"\\n\\t %s\", [idx2word(_, word2idx_outputs) for _ in output_input_integer_seq[argmax]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSyzIGqpR6FR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrXti4M83-sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(reprlib.repr(word2idx_outputs), len(word2idx_outputs))\n",
        "def idx2word(idx, word2idx):\n",
        "  return [k for k, v in word2idx.items() if v == idx]\n",
        "print([idx2word(elm, word2idx_outputs) for elm in range(1, 20 + 1)], range(1, 20 + 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzbEmpedoG_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding \n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "# glove.6B.zip http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "if loc in ['colab']:\n",
        "  glove_file_loc = r\"/content/drive/My Drive/data/glove.6B.100d.txt\"\n",
        "  if not Path(glove_file_loc).exists():\n",
        "    os.chdir(r\"/content/drive/My Drive/data\")\n",
        "    ! wget -c http://nlp.stanford.edu/data/glove.6B.zip\n",
        "    !unzip glove.6B.zip glove.6B.100d.txt\n",
        "    os.chdir(\"/content\")\n",
        "else:\n",
        "  glove_file_loc = r\"file_loc\"\n",
        "assert Path(glove_file_loc).exists(), f\" file [{glove_file_loc}] does not exists.\"\n",
        "\n",
        "# glove_file = open(r'/content/drive/My Drive/data/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "with open(r'/content/drive/My Drive/data/glove.6B.100d.txt', encoding=\"utf8\") as glove_file:\n",
        "  for line in glove_file:\n",
        "      records = line.split()\n",
        "      word = records[0]\n",
        "      vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "      embeddings_dictionary[word] = vector_dimensions\n",
        "# glove_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3leOyFwBUoOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# glove_file = open(r'/content/drive/My Drive/data/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "# line = next(glove_file)\n",
        "# print(line)  # the -0.038194 -0.24487 0.72812 -0.39961 0.083172 \n",
        "# glove_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZtwd0EY2_7j",
        "colab_type": "text"
      },
      "source": [
        "for inputs: Recall that we have 3523 unique words in the input. We will create a matrix where the row number will represent the integer value for the word and the columns will correspond to the dimensions of the word. This matrix will contain the word embeddings for the words in our input sentences.\n",
        "\n",
        "For outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXlqn4CizQD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_outputs) + 1)\n",
        "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
        "for word, index in word2idx_outputs.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z5DxAx1qbyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 0\n",
        "logger.debug(\"embedding_matrix.shape: %s\", embedding_matrix.shape)  # 9025 + 1, (9026, 100)\n",
        "logger.debug(\" embedding_matrix[0]: %s, len: %s\", embedding_matrix[0], len(embedding_matrix[0]))  # all zeros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWixPo0Nhj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(embeddings_dictionary[\"ill\"][:10])\n",
        "print(embeddings_dictionary[\"ill\"][-10:])\n",
        "# [ 0.12648 0.1366 0.22192 -0.025204 -0.7197 0.66147 0.48509 0.057223 0.13829 -0.26375 ]\n",
        "# ...\n",
        "# [-0.37322 0.50538   0.59171   0.46534  -0.42482   0.83265 0.081548 -0.44147 -0.084311 -1.2304  ]  -"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3crBAe5Sp86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_ill = word2idx_outputs['ill']  # 3446\n",
        "emd_ill = embedding_matrix[idx_ill]\n",
        "print(emd_ill[:5], '\\n', emd_ill[-5:])\n",
        "# [ 0.12648     0.1366      0.22192    -0.025204   -0.71969998] \n",
        "# [ 0.83265001  0.081548   -0.44147    -0.084311   -1.23039997]  # check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if3dz4n2uYIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger.debug(\"EMBEDDING_SIZE: %s\", EMBEDDING_SIZE)\n",
        "assert embedding_matrix.shape[1] == EMBEDDING_SIZE  # (9026, 100)[1] == 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhV4NkbwceP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding layer\n",
        "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ew9ugjHcoHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(embedding_layer)  # keras.layers.embeddings.Embedding object "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMlPGsbWdL3O",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Model\n",
        "Therefore, the final shape of the output will be:\n",
        "```shell\n",
        "(number of inputs, length of the output sentence, the number of words in the output)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwKpInUVdrxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "decoder_targets_one_hot = np.zeros((\n",
        "        len(input_sentences),\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    ),\n",
        "    dtype='float32'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqZt9LKkTmGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(word2idx_inputs[\"i'm\"])  # in the article eng-fra \n",
        "# print(word2idx_inputs[\"ill\"])  # 6 539\n",
        "\n",
        "print(word2idx_outputs[\"i'm\"])\n",
        "print(word2idx_outputs[\"ill\"])\n",
        "# 31, 3446\n",
        "idx2word(31, word2idx_outputs), idx2word(3446, word2idx_outputs), idx2word(31, word2idx_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNqY8BNQRkrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logger.debug(\"decoder_targets_one_hot.shape: %s\", decoder_targets_one_hot.shape)  \n",
        "# eng-cnm swapped: out is en (20000, 13, 9026): 20000 sents, sent lenght 13, vocabs 9026"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo7MAdOoXOt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from comments john lee\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(repr(decoder_output_sequences[:3]))  # 3466,1 (hi., eos), 2276,1, run. eos "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grw9_jibVyRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i, d in enumerate(decoder_output_sequences):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot[i, t, word] = 1\n",
        "from pprint import pprint\n",
        "t0 = decoder_targets_one_hot[:1]\n",
        "print(t0.shape, t0[0, 0, 3466], t0[0, 1, 1], idx2word(3466, word2idx_outputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XttLJnhZeri2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder\n",
        "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(LSTM_NODES, return_state=True)\n",
        "\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "encoder_states = [h, c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZWf-ruXfAMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the decoder LSTM\n",
        "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
        "\n",
        "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wyZezumfdFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PcYFFnmfmL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The next step is to compile the model:\n",
        "\n",
        "model = Model([encoder_inputs_placeholder,\n",
        "  decoder_inputs_placeholder], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abP0pyAhfu1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's plot our model to see how it looks:\n",
        "\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-cFnzdN0veM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model using the fit() method:\n",
        "\n",
        "r = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets_one_hot,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    # epochs=1,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjgTsi2PW5Q_",
        "colab_type": "text"
      },
      "source": [
        "## Modifying the Model for Predictions\n",
        "\n",
        "**While training**\n",
        "\n",
        "`// Inputs on the left of Encoder/Decoder, outputs on the right.`\n",
        "\n",
        "* step 1: -\n",
        "  I'm ill -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> je + dec(h1,c1)\n",
        "\n",
        "* step 2:\n",
        "\n",
        "enc(h1,c1) + je -> Decoder -> suis + dec(h2,c2)\n",
        "\n",
        "* step 3:\n",
        "\n",
        "enc(h2,c2) + suis -> Decoder -> malade. + dec(h3,c3)\n",
        "\n",
        "* step 3:\n",
        "\n",
        "enc(h3,c3) + malade. -> Decoder -> <eos> + dec(h4,c4) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEAHxQJt7Zn6",
        "colab_type": "text"
      },
      "source": [
        "The encoder model remains the same:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxrwfQru7bF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr57iPRpYvEA",
        "colab_type": "text"
      },
      "source": [
        "**During predictions**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "// Inputs on the left of Encoder/Decoder, outputs on the right.\n",
        "\n",
        "Step 1:\n",
        "\n",
        "I'm ill -> Encoder -> enc(h1,c1)\n",
        "\n",
        "enc(h1,c1) + <sos> -> Decoder -> y1(je) + dec(h1,c1)\n",
        "\n",
        "step 2:\n",
        "\n",
        "enc(h1,c1) + y1 -> Decoder -> y2(suis) + dec(h2,c2)\n",
        "\n",
        "step 3:\n",
        "\n",
        "enc(h2,c2) + y2 -> Decoder -> y3(malade.) + dec(h3,c3)\n",
        "\n",
        "step 3:\n",
        "\n",
        "enc(h3,c3) + y3 -> Decoder -> y4(<eos>) + dec(h4,c4)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzqry1-XW_9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbgOxi9KC7rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
        "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJtjkiBPDX94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTK2QQYpDeUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBaQCO2wDgB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_states = [h, c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47xRmf_RDkQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmM5sAIvDsVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(decoder_model, to_file='model_plot_dec.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSCPjz3CAilw",
        "colab_type": "text"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4zJU9V-AvuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2word_input = {v: k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v: k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohlPUCvZBChs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a_wKRKGBbCp",
        "colab_type": "text"
      },
      "source": [
        "## Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qmV7oAjBeTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "logzero.loglevel(10)\n",
        "\n",
        "i = np.random.choice(len(input_sentences))\n",
        "logger.info(\"input_sentences %s\", i)\n",
        "input_seq = encoder_input_sequences[i:i+1]\n",
        "logger.debug(\"input_seq %s\", input_seq)\n",
        "translation = translate_sentence(input_seq)\n",
        "print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_wvdRegBz0M",
        "colab_type": "text"
      },
      "source": [
        "## Concluding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD61ueefEMZA",
        "colab_type": "text"
      },
      "source": [
        "## Other Misc Notes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APePrgUEQkng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ############## misc notes\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "# coloredlogs\n",
        "try:\n",
        "  import coloredlogs\n",
        "except ModuleNotFoundError:\n",
        "  get_ipython().system(\"pip install coloredlogs\")\n",
        "  import coloredlogs\n",
        "\n",
        "coloredlogs.install(level='DEBUG')\n",
        "logger.debug(reprlib.repr(input_sentences))\n",
        "logger.debug(reprlib.repr(output_sentences_inputs))\n",
        "logger.debug(reprlib.repr(output_sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8h0lp6BRT1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/joshbode/58fac7ababc700f51e2a9ecdebe563ad\n",
        "import sys\n",
        "import logging\n",
        "from typing import Optional, Dict\n",
        "\n",
        "try:\n",
        "  import colorama\n",
        "except ModuleNotFoundError:\n",
        "  get_ipython().system(\"pip install colorama\")\n",
        "from colorama import Fore, Back, Style\n",
        "\n",
        "\n",
        "class ColoredFormatter(logging.Formatter):\n",
        "    \"\"\"Colored log formatter.\"\"\"\n",
        "\n",
        "    def __init__(self, *args, colors: Optional[Dict[str, str]]=None, **kwargs) -> None:\n",
        "        \"\"\"Initialize the formatter with specified format strings.\"\"\"\n",
        "\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.colors = colors if colors else {}\n",
        "\n",
        "    def format(self, record) -> str:\n",
        "        \"\"\"Format the specified record as text.\"\"\"\n",
        "\n",
        "        record.color = self.colors.get(record.levelname, '')\n",
        "        record.reset = Style.RESET_ALL\n",
        "\n",
        "        return super().format(record)\n",
        "\n",
        "\n",
        "formatter = ColoredFormatter(\n",
        "    '{asctime} |{color} {levelname:8} {reset}| ln-{lineno} |{color} {message}',\n",
        "    # '{asctime} |{color} {levelname:8} {reset}| {name} | {message}',\n",
        "    style='{', datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    colors={\n",
        "        'DEBUG': Fore.CYAN,\n",
        "        'INFO': Fore.GREEN,\n",
        "        'WARNING': Fore.YELLOW,\n",
        "        'ERROR': Fore.RED,\n",
        "        'CRITICAL': Fore.RED + Back.WHITE + Style.BRIGHT,\n",
        "    }\n",
        ")\n",
        "\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setFormatter(formatter)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger = logging.getLogger()\n",
        "logger.handlers[:] = []\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "#logger.setLevel(logging.INFO)\n",
        "\n",
        "logger.debug(\"debug\")\n",
        "logger.info(\"info: %s\", 'info')\n",
        "logger.warning(\"warning\")\n",
        "logger.error(\"erorr\")\n",
        "from logzero import logger\n",
        "logzero.loglevel(20)\n",
        "logzero.formatter(formatter)\n",
        "logger.debug('ddd')\n",
        "logger.info('iii')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}